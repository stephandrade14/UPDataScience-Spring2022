{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Week 4 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Spatial joins\n",
    "In the Data Wrangling lecture, we used the [dataset on California traffic collisions](https://tims.berkeley.edu/help/SWITRS.php). Let's revisit that dataset, but make use of the spatial information this time.\n",
    "\n",
    "Below is the code that we used in lecture to load in the data. It's just one month from Ventura County; if you want more, you'll need to register.\n",
    "\n",
    "An aside: Note that the paths are a little different because the data files are under `lectures/data`, not `classes/data`. The `..` directory means \"up one level.\"\n",
    "\n",
    "The `os` module has some useful functions for directory and file operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52838cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/stephanieandrade/Documents/GitHub/UPDataScience-Spring2022/Classes and Lectures'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# see what directory we are in\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d630594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SAndrade Class 2 solutions.ipynb',\n",
       " 'SAndrade 7 Scraping craigslist.ipynb',\n",
       " 'SAndrade Class 4 solutions.ipynb',\n",
       " 'SAndrade 6 Scraping permits.ipynb',\n",
       " 'SAndrade Class 3 solutions.ipynb',\n",
       " 'SAndrade 5 The Socrata API.ipynb',\n",
       " 'readme.md',\n",
       " 'SAndrade 4 Getting census data.ipynb',\n",
       " 'SAndrade Class 1 solutions.ipynb',\n",
       " '.ipynb_checkpoints',\n",
       " 'SAndrade 9 Spatial joins.ipynb',\n",
       " 'SAndrade 8 Data wrangling.ipynb',\n",
       " 'SAndrade 3 APIs.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the current directory contents\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a805635c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md', 'Homework', '.git', 'Classes and Lectures']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the parent directory contents\n",
    "os.listdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d237be3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Lectures/data/Collisions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load in the data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m collisionDf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../Lectures/data/Collisions.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uds/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uds/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uds/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uds/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uds/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/uds/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Lectures/data/Collisions.csv'"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "import pandas as pd\n",
    "collisionDf = pd.read_csv('../Lectures/data/Collisions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30faed6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> What columns provide the spatial coordinates? What problems might there be with each one?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d1ce7",
   "metadata": {},
   "source": [
    "*Hint*: Look at the [codebook](https://tims.berkeley.edu/help/SWITRS.php) to see the column definitions. You have two choices - there are minor differences.\n",
    "    \n",
    "*Hint*: Use `head()` to look at the first rows of the relevant columns . What problems are there with each of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b41e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "collisionDf[['LATITUDE','LONGITUDE', 'POINT_X', 'POINT_Y']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ee0f1",
   "metadata": {},
   "source": [
    "You'll notice that there is some missing data. There is a helpful function, `fillna()` in pandas that will fill in missing values from another columns. Take a look at the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collisionDf.fillna?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2fa65",
   "metadata": {},
   "source": [
    "Note that the `value` argument can be a scalar (e.g. you can replace all NaNs with 0), or another column (e.g. you can replace all NaNs in the `LONGITUDE` column with values from `POINT_X`.) [See the example here](https://stackoverflow.com/questions/30357276/how-to-pass-another-entire-column-as-argument-to-pandas-fillna).\n",
    "\n",
    "Also note that there is an `inplace` keyword argument, which we've seen before with the `set_index()` function. It works the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549f5a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Fill in the missing values in the latitude and longitude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "collisionDf.LONGITUDE.fillna(collisionDf.POINT_X, inplace=True)\n",
    "collisionDf.LATITUDE.fillna(collisionDf.POINT_Y, inplace=True)\n",
    "collisionDf[['LATITUDE','LONGITUDE', 'POINT_X', 'POINT_Y']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365e547",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Convert your dataframe to a GeoDataFrame. Call it <strong>collisionGdf</strong>. \n",
    "    \n",
    "Do a quick-and-dirty plot of the points to satisfy yourself that it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deaca3b",
   "metadata": {},
   "source": [
    "*Hint*: The geopandas `points_from_xy()` function will be helpful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "collisionGdf = 9999\n",
    "\n",
    "import geopandas as gpd\n",
    "collisionGdf = gpd.GeoDataFrame(collisionDf, geometry=gpd.points_from_xy(collisionDf.LONGITUDE, collisionDf.LATITUDE, \n",
    "                                          crs='EPSG:4326'))\n",
    "\n",
    "collisionGdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f20a6",
   "metadata": {},
   "source": [
    "What do we join the collision data to?\n",
    "\n",
    "Let's do two separate analyses:\n",
    "* Look at the transportation justice aspects of road safety, through joining the collision data to the CalEnviroScreen data\n",
    "* Look at school safety, through joining the collision data to school locations\n",
    "\n",
    "## Collisions and neighborhood characteristics\n",
    "\n",
    "Let's start with the EnviroScreen. We already used this data set, so let's load it into `geopandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroscreen = gpd.read_file('../Lectures/data/CalEnviroScreen/CES4 Final Shapefile.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd0b18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Drop all the rows from <strong>enviroscreen</strong> except for those in Ventura County.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277b197",
   "metadata": {},
   "source": [
    "*Hint*: The `df=df[...]` syntax is the easiest way to do this. It will just keep the rows where the condition inside the `[ ]` is `True`.\n",
    "\n",
    "For example, this will only keep the census tracts with population greater than 5000.\n",
    "\n",
    "`enviroscreen = enviroscreen[enviroscreen.TotPop19>5000]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d59465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This returns a boolean Series\n",
    "enviroscreen.TotPop19>5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we pass that series to only return values from the DataFrame where the condition evaluated to True\n",
    "# Note that rows with index 4581, 4583, etc. have been filtered out\n",
    "enviroscreen[enviroscreen.TotPop19>5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75342ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "enviroscreen = enviroscreen[enviroscreen.County=='Ventura']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89523f4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Add the number of collisions to each census tract in the EnviroScreen data frame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e568d4",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Think about projections!\n",
    "- I suggest a multistep process\n",
    "  - What census tract is the collision in? Do a spatial join to add the tract (which is in `enviroscreen`) to the collisions dataframe.\n",
    "  - How many collisions are there in each tract? Use `groupby`! Create a new dataframe with the tract-level counts.\n",
    "  - Then you can join these counts back to `enviroscreen` using the `Tract` column\n",
    "  \n",
    "  \n",
    "If you get an error in the final join, `Other Series must have a name`, you can add a name to a pandas `Series` as follows (remember that a Series is like a one-column DataFrame):\n",
    "\n",
    "    `your_series_name.name = 'n_collisions'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e407307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# get the census tract of each collision through joining\n",
    "collisionGdf2 = gpd.sjoin(collisionGdf.to_crs('EPSG:3310'), enviroscreen)\n",
    "\n",
    "# check there are the same number of rows\n",
    "print(len(collisionGdf), len(collisionGdf2))\n",
    "\n",
    "# looks like we lost a few, which we should investigate later on. \n",
    "# Maybe there is missing lat/lon? Or spatial imprecision?\n",
    "\n",
    "# get the tract-level counts\n",
    "tractcounts = collisionGdf2.groupby('Tract').size()\n",
    "\n",
    "# we need to give it a name\n",
    "tractcounts.name = 'n_collisions'\n",
    "\n",
    "# join back to enviroscreen\n",
    "enviroscreen = enviroscreen.set_index('Tract').join(tractcounts)\n",
    "\n",
    "# replace the missing values with zeros (no collisions)\n",
    "enviroscreen.n_collisions.fillna(0, inplace=True)\n",
    "\n",
    "# we should do our standard checks here for number of rows, describing the column, a quick-and-dirty plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroscreen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59a5b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Plot the relationship between traffic collisions and the Enviroscreen score, and/or some of the demographic indicators.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2ef151",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- The `CIscoreP` gives the percentile of each census tract. The higher the score, the more the pollution burden and/or vulnerability as measured via demographic characteristics. Disadvantaged communities are defined as those with a percentile of 75 or greater.\n",
    "- Try boxplots, scatterplots, or the `seaborn.regplot` (a scatter plot with the line of best fit)\n",
    "- You can also map the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# create a binary variable for Disadvantaged Community (in the top quartile)\n",
    "enviroscreen['disadv'] = enviroscreen.CIscoreP>=75\n",
    "enviroscreen.disadv.mean()\n",
    "\n",
    "# box plot\n",
    "#enviroscreen.boxplot('n_collisions', by='disadv')\n",
    "\n",
    "# scatter plot\n",
    "# need to drop the negative values first\n",
    "enviroscreen[enviroscreen.CIscoreP>0].plot(y='n_collisions', x='CIscoreP', kind='scatter')\n",
    "\n",
    "# with regression line\n",
    "import seaborn as sns\n",
    "sns.regplot(x='CIscoreP', y='n_collisions', data=enviroscreen[enviroscreen.CIscoreP>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966a1bf",
   "metadata": {},
   "source": [
    "## Schools\n",
    "Now let's do a join to the schools dataset. [Download the shapefile with the point location of schools](https://data-cdegis.opendata.arcgis.com/datasets/CDEGIS::california-schools-2019-20/about). If you put it in your class repository in the `classes/` directory, you won't have to specify the path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c3cb0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Load the schools data into a geodataframe called <strong>schools</strong>. Drop all the schools that are not in Ventura County. (You can use the <strong>CountyName</strong> column.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5096cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "schools = gpd.read_file('California_Schools_2019-20/SchoolSites1920.shp')\n",
    "schools = schools[schools.CountyName=='Ventura']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca0086c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong>In my version of the data, it looks like there is an errant school in the far north of California, that only purports to be in Ventura County. Identify and drop it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff28c25",
   "metadata": {},
   "source": [
    "*Hint*: There are several ways to approach this. My approach would be to:\n",
    "\n",
    "* Create a new column with the `y` coordinate: `schools['y'] = schools.geometry.y`\n",
    "* Sort by this column to find the row with the highest value of `y`\n",
    "* Drop that row (e.g. `schools = schools[schools.y<some_value_of_y]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# diagnose the problem\n",
    "schools.plot()\n",
    "\n",
    "# add a new column\n",
    "schools['y'] = schools.geometry.y\n",
    "\n",
    "# look for highest value\n",
    "print(schools.sort_values(by='y').y.tail())\n",
    "\n",
    "# drop the outlier\n",
    "schools = schools[schools.y<4.5e6]\n",
    "\n",
    "# check it worked\n",
    "schools.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b02b573",
   "metadata": {},
   "source": [
    "Now, how do we join the schools to the collision data? Both are point geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24327cee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Think conceptually about different options to do the join. It can help to do some sketches.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715551f4",
   "metadata": {},
   "source": [
    "There are several ways to do this, but let's look at the number of collisions within a 1km radius of each school. Then, we can follow a five-step process:\n",
    "* Make sure we are working in a suitable projection\n",
    "* Create a 1km buffer around each school\n",
    "* Do a spatial join between collisions and (buffered) schools, attaching school ids to the collision geodataframe\n",
    "* Group by the school id to get the counts\n",
    "* Join back to the school data\n",
    "\n",
    "\n",
    "*NOTE*: Buffering a geometry isn't usually the most efficient way to get this count, because creating new geometries takes time and memory. Instead, we could get the distances between each school and each collision, and count the number with a distance (like we did in the video lecture). That's a little more complicated, and for a small dataset the speed penalty is going to be minimal. But for large datasets, try and avoid creating buffer geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09baf9bb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Find the relevant State Plane coordinate reference system for Ventura County (choose the one in meters, not feet). Convert both <strong>schools</strong> and <strong>collisionGdf</strong> to that crs.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f51968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# I Googled Ventura State Plane meters and found it was California Zone 5\n",
    "# Then I used spatialreference.org to get the EPSG code: 3497\n",
    "\n",
    "collisionGdf.to_crs('EPSG:3497', inplace=True)\n",
    "schools.to_crs('EPSG:3497', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe419b47",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Convert the school geometry into a 1km buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784a282",
   "metadata": {},
   "source": [
    "*Hint*: The `buffer()` function will work here. It will create a new geometry, which you can use to overwrite the old one. You can buffer lines and polygons as well as points.\n",
    "\n",
    "For example: `gdf.geometry = gdf.geometry.buffer(100)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39703cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "schools.geometry = schools.geometry.buffer(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c363214c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Add a column to the schools data with the number of collisions within 1km."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2768cfb",
   "metadata": {},
   "source": [
    "*Hint*: You should now be able to follow steps 3-5 using the same procedure as with the EnviroScreen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# The Scode looks promising as an id column. Let's check that it is unique\n",
    "print(schools.SCode.is_unique)\n",
    "\n",
    "# spatial join\n",
    "tmpgdf = gpd.sjoin(schools, collisionGdf, predicate='intersects')\n",
    "tmpgdf.head() # check it worked\n",
    "\n",
    "# group by\n",
    "collision_counts = tmpgdf.groupby('SCode').size()\n",
    "collision_counts.name = 'n_collisions'\n",
    "collision_counts.head() # check it worked\n",
    "\n",
    "# join back\n",
    "schools = schools.set_index('SCode').join(collision_counts)\n",
    "schools.n_collisions.fillna(0, inplace=True)\n",
    "schools.n_collisions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ff5cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Map the number of collisions near each school."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af029d17",
   "metadata": {},
   "source": [
    "*Hints*: \n",
    "* There are several ways to do this. You could do proportional markers (you might need to scale the `n_collisions` column). Add a basemap too!\n",
    "* Note that you can't do proportional circles for the schools polygon geometry - just for points. You'll need to convert the geometry back to the centroids (`gdf.geometry = gdf.geometry.centroid`). (Or you could have saved a copy of the old geodataframe and joined the collision counts back to that.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as ctx\n",
    "\n",
    "schools.geometry = schools.geometry.centroid\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# my first try\n",
    "# looks like we need to make the markers bigger\n",
    "#schools.plot(markersize='n_collisions', ax=ax)\n",
    "\n",
    "schools['n_collisions_scaled'] = schools.n_collisions*10\n",
    "# plot all the schools first, so we don't ignore those ones with zero collisions\n",
    "schools.to_crs('EPSG:3857').plot(ax=ax, markersize=0.5, color='k')\n",
    "# plot the proportional markers\n",
    "schools.to_crs('EPSG:3857').plot(markersize='n_collisions_scaled', color='b', ax=ax)\n",
    "\n",
    "ctx.add_basemap(ax=ax, alpha=0.5, zoom=13)\n",
    "ax.set_title('Number of collisions near each school')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f6e1c6",
   "metadata": {},
   "source": [
    "## Joins gone wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fefc9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Fix the errors in each cell below. (Not all of them generate Python exceptions, but the join might not be what you expect.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, reload a clean copy of the data\n",
    "collisionDf = pd.read_csv('../Lectures/data/Collisions.csv')\n",
    "enviroscreen = gpd.read_file('../Lectures/data/CalEnviroScreen/CES4 Final Shapefile.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join between collisions and EnviroScreen\n",
    "joined = gpd.sjoin(collisionDf, enviroscreen, predicate='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14511057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of collisions in each census tract\n",
    "collisionGdf = gpd.GeoDataFrame(collisionDf, \n",
    "                                geometry=gpd.points_from_xy(collisionDf.LONGITUDE.fillna(collisionDf.POINT_X), \n",
    "                                                            collisionDf.LATITUDE.fillna(collisionDf.POINT_Y), \n",
    "                                          crs='EPSG:4326'))\n",
    "\n",
    "joined = gpd.sjoin(collisionGdf, enviroscreen, predicate='contains')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>What you should have learned</h3>\n",
    "<ul>\n",
    "  <li>Gain more practice with spatial joins</li>\n",
    "  <li>Understand how to buffer geometries.</li>\n",
    "  <li>Get practice with troubleshooting spatial joins.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
